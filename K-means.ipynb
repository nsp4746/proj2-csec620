{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import re, random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# K Means Code was taken and modified from here: https://github.com/aihubprojects/Machine-Learning-From-Scratch/blob/master/K-Means%20from%20Scratch.ipynb \n",
    "#  I followed this tutorial as well to help understand how to prepare and use the data: https://www.geeksforgeeks.org/kmeans-clustering-and-pca-on-wine-dataset/\n",
    "\n",
    "WINE_DATA = pd.read_csv(\"./wine/wine.data\", index_col=0) # Do index_col=0 to drop the class identifier. \n",
    "\n",
    "IRIS_DATA = pd.read_csv(\"./Iris/iris.data\")\n",
    "\n",
    "# K-means clustering algorithm\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    A simple K-means clustering implementation.\n",
    "\n",
    "    This class implements the K-means clustering algorithm to group data points into `k` clusters\n",
    "    based on their distance to the cluster centroids. The centroids are initialized randomly, and\n",
    "    the algorithm iterates to minimize the within-cluster variance.\n",
    "\n",
    "    Attributes:\n",
    "        k (int): The number of clusters to form.\n",
    "        max_iters (int): The maximum number of iterations for the algorithm to converge. Default is 100.\n",
    "        centroids (np.ndarray): The coordinates of the cluster centroids.\n",
    "        clusters (np.ndarray): The cluster labels for each data point.\n",
    "    \n",
    "    Methods:\n",
    "        fit(X): Fits the K-means model to the data by determining the cluster centroids and assigning data points to clusters.\n",
    "        predict(X): Predicts the nearest cluster for a new set of data points based on the fitted centroids.\n",
    "        _initialize_centroids(X): Initializes the centroids by randomly selecting data points.\n",
    "        _compute_distance(a, b): Computes the Euclidean distance between two points.\n",
    "        _assign_clusters(X): Assigns each data point to the nearest cluster centroid.\n",
    "        _update_centroids(X): Updates the centroids based on the mean of the data points assigned to each cluster.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=3, max_iters=100):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.centroids = None\n",
    "        self.clusters = None\n",
    "        \n",
    "    def euclidean_distance(self, point1, point2):\n",
    "        return np.sqrt(np.sum((point1 - point2)**2))\n",
    "    \n",
    "    def fit(self, X):\n",
    "    \n",
    "        np.random.seed(random.randint(1,100))  # for reproducibility\n",
    "        random_indices = np.random.permutation(X.shape[0])[:self.k]\n",
    "        self.centroids = X[random_indices]\n",
    "        \n",
    "        for i in range(self.max_iters):\n",
    "            self.clusters = self.create_clusters(X)\n",
    "            old_centroids = self.centroids\n",
    "            self.centroids = self.calculate_centroids(X)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "    \n",
    "    def create_clusters(self, X):\n",
    "        clusters = [[] for _ in range(self.k)]\n",
    "        for idx, point in enumerate(X):\n",
    "            closest_centroid = np.argmin([self.euclidean_distance(point, centroid) for centroid in self.centroids])\n",
    "            clusters[closest_centroid].append(idx)\n",
    "        return clusters\n",
    "    \n",
    "    def calculate_centroids(self, X):\n",
    "        centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for cluster_idx, cluster in enumerate(self.clusters):\n",
    "            if cluster:  # Avoid empty clusters\n",
    "                centroids[cluster_idx] = np.mean(X[cluster], axis=0)\n",
    "        return centroids\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([np.argmin([self.euclidean_distance(x, centroid) for centroid in self.centroids]) for x in X])"
   ],
   "id": "45c615644f86eaaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_column_names():\n",
    "    \"\"\"\n",
    "    Obtains column names for the respective datasets as the datasets come unlabeled\n",
    "    \n",
    "    It takes the filepath from the directory, creates a list for the columns as well as line counter. \n",
    "    Line counter counts the lines in the file until it reaches a certain threshold, where it then adds those lines to the list of columns. The lines will not change unless the .names files are modifiied.\n",
    "    After adding the column names to a list, regular expressions are used to clean up the strings (remove numbers). \n",
    "    \n",
    "    :return: two python lists consisting of columns\n",
    "    \"\"\"\n",
    "    wine_names = \"./wine/wine.names\"\n",
    "    iris_names = \"./Iris/iris.names\"\n",
    "    wine_columns = []\n",
    "    iris_columns = []\n",
    "    \n",
    "    wine_line_counter = 0\n",
    "    iris_line_counter = 0\n",
    "    \n",
    "    with open(wine_names) as f:\n",
    "        for line in f:\n",
    "            wine_line_counter += 1\n",
    "            if(wine_line_counter > 57 and wine_line_counter <= 70):\n",
    "                line = line.strip()\n",
    "                wine_columns.append(line)\n",
    "    f.close()\n",
    "    wine_columns =  [re.sub(r'^\\d+\\)\\s*', '', column) for column in wine_columns]\n",
    "    \n",
    "    with open(iris_names) as f:\n",
    "        for line in f:\n",
    "            iris_line_counter += 1\n",
    "            if(iris_line_counter > 50 and iris_line_counter < 56):\n",
    "                line = line.strip()\n",
    "                iris_columns.append(line)\n",
    "    f.close()\n",
    "    iris_columns =  [re.sub(r'^\\d+\\.\\s*', '', column) for column in iris_columns]\n",
    "    \n",
    "    print(wine_columns)\n",
    "    print(iris_columns)\n",
    "    \n",
    "    return wine_columns, iris_columns"
   ],
   "id": "ad8c84108f7c84c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def wine_classification(wine_columns):\n",
    "    \"\"\"\n",
    "    This function aims to classify different types of Wines via a dataset and using K-means clustering. It also processes the dataframe prior to use and uses seaborn to plot the dataset as well as to create a heatmap.     \n",
    "    :param wine_columns: The column headers of the Wine dataset\n",
    "    \"\"\"\n",
    "    df = WINE_DATA\n",
    "    df.columns = wine_columns\n",
    "    df.info()\n",
    "    scaler = StandardScaler()\n",
    "    transformed_features = scaler.fit_transform(df)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(transformed_features, columns=df.columns)\n",
    "    print(scaled_df.head(2))\n",
    "    \n",
    "    kmeans = KMeans(k=3) # three clusters since 3 different types of wine \n",
    "    kmeans.fit(scaled_df.values)  # Fit the model on the scaled features\n",
    "    \n",
    "    # Get the predicted cluster labels\n",
    "    clusters = kmeans.predict(scaled_df.values)\n",
    "    \n",
    "    # Add the cluster labels to the DataFrame for analysis\n",
    "    scaled_df['Cluster'] = clusters\n",
    "    print(scaled_df.head())\n",
    "\n",
    "    # Perform PCA to reduce to 2 components for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA only on the numerical features (exclude 'Cluster' column)\n",
    "    pca_result = pca.fit_transform(scaled_df.drop('Cluster', axis=1))\n",
    "\n",
    "    # Create a new DataFrame for the PCA results and the cluster labels\n",
    "    pca_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])\n",
    "    pca_df['Cluster'] = clusters\n",
    "\n",
    "    # Plot the PCA results with clusters\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', s=100, alpha=0.8)\n",
    "    plt.title('Wine Clusters Visualized using PCA')\n",
    "    plt.show()\n",
    "\n",
    "    component_df=pd.DataFrame(pca.components_,index=['PCA1',\"PCA2\"],columns=df.columns)\n",
    "    # Heat map\n",
    "    sns.heatmap(component_df)\n",
    "    plt.show() "
   ],
   "id": "2698a1ca49cc7f71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def iris_classification(iris_columns):\n",
    "    \"\"\"\n",
    "    This function aims to classify different types of Iris' flowers via a dataset and using K-means clustering. It also processes the dataframe prior to use and uses seaborn to plot the dataset as well as to create a heatmap. \n",
    "    :param iris_columns: a list of column headers\n",
    "    \"\"\"\n",
    "    df = IRIS_DATA\n",
    "    df.columns = iris_columns\n",
    "    df.drop(\"class:\",axis=1,inplace=True)\n",
    "    df.info()\n",
    "    scaler = StandardScaler()\n",
    "    transformed_features = scaler.fit_transform(df)\n",
    "    scaled_df = pd.DataFrame(transformed_features, columns=df.columns)\n",
    "    print(scaled_df.head(2))\n",
    "    \n",
    "    kmeans = KMeans(k=3) # three clusters since 3 different types of wine \n",
    "    kmeans.fit(scaled_df.values)  # Fit the model on the scaled features\n",
    "    \n",
    "    # Get the predicted cluster labels\n",
    "    clusters = kmeans.predict(scaled_df.values)\n",
    "    \n",
    "    # Add the cluster labels to the DataFrame for analysis\n",
    "    scaled_df['Cluster'] = clusters\n",
    "    print(scaled_df.head())\n",
    "\n",
    "    # Perform PCA to reduce to 2 components for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA only on the numerical features (exclude 'Cluster' column)\n",
    "    pca_result = pca.fit_transform(scaled_df.drop('Cluster', axis=1))\n",
    "\n",
    "    # Create a new DataFrame for the PCA results and the cluster labels\n",
    "    pca_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])\n",
    "    pca_df['Cluster'] = clusters\n",
    "\n",
    "    # Plot the PCA results with clusters\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', s=100, alpha=0.8)\n",
    "    plt.title('Different Types of Iris Flowers Visualized using PCA')\n",
    "    plt.show()\n",
    "    \n",
    "    component_df=pd.DataFrame(pca.components_,index=['PCA1',\"PCA2\"],columns=df.columns)\n",
    "    # Heat map\n",
    "    sns.heatmap(component_df)\n",
    "    plt.show()"
   ],
   "id": "51960501c30b9a5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    wine_columns, iris_columns = get_column_names()\n",
    "    wine_classification(wine_columns)\n",
    "    iris_classification(iris_columns)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "7d90823e55219356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9cf19642546b7285"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
